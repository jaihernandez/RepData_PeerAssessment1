segments <- seq(1, 20)
##  Create combinations of variables
A <- expand.grid(action_codes, areas, segments)
names(A) <- c("action_code", "area", "segment")
A <- A[with(A, order(action_code, area)),]
A$segment <- rep(sample(1:20, 20, replace = FALSE), 154)
A$dollars <- rep(0,dim(A)[1])
for (i in 1:length(areas)){
for (j in 1:length(action_codes)){
AAC <- max(1500, rnorm(1, mean = 9500, sd = 5000))
A$dollars[((A[,1]==action_codes[j]) & (A[,2]==areas[i]))] <- AAC*
exp(-0.05 * A$segment[((A[,1]==action_codes[j]) & (A[,2]==areas[i]))])
}
}
A$dollars <- round(A$dollars,0)
# Get the cumulative sum dollars so we can optimize on a max objective function
CumA <- A %>%
arrange(action_code, area, segment) %>%
mutate(dollars =  round(dollars,0),
cum.Dol = ave(dollars, cumsum(segment == 1), FUN = cumsum)) %>%
ungroup() %>%
group_by(action_code, area) %>%
mutate(hpc = sample.int(n())) %>%
dplyr::rename(rank = segment)
CumA <- as.data.frame(CumA)
#### Overall Fitted Model ####
# Get a fitted equation for the cumulative dollars (y = 40583ln(x) - 13497)
overallmodel <- nls(cum.Dol ~ coef*log(rank) - int, start = list(coef=40000, int = 10000), data = CumA)
summary(overallmodel)
# Create a model for each AAC
models = CumA %>%
group_by(action_code, area) %>%
do(aac.fit = nls(cum.Dol ~ coef*log(rank) - int, start = list(coef=40000, int = 10000), data = CumA))
# Get the coefficients for each AAC
AAC.estimates <- tidy(models, aac.fit)
AAC.estimates <- data.frame(split(AAC.estimates, AAC.estimates$term))
AAC.estimates <- select(AAC.estimates, coef.action_code, coef.area, coef.estimate, int.estimate)
AAC.estimates <- dplyr::rename(AAC.estimates, action_code = coef.action_code, area = coef.area)
CumA <- merge(CumA, AAC.estimates, by=c("action_code", "area"))
# Get the Predictions for each AAC
preds <- augment(models, aac.fit)
preds <- preds %>%
select(action_code, area, rank, .fitted) %>%
dplyr::rename(predicted = ".fitted")
preds <- unique(preds)
CumA <- merge(CumA, preds, by=c("action_code", "area", "rank"))
# Get the summary statistics
mod.summ <- glance(models, aac.fit)
# Add the overall fitted values to the dataframe
CumA$fitted.overall <- predict(overallmodel)
CumA <- select(CumA, action_code, area, rank, dollars, cum.Dol, hpc, coef.estimate, int.estimate, predicted)
all.params <- overallmodel$m$getPars()
overall.coef <- all.params[1]
overall.int <- all.params[2]
CumA$coef.estimate <- as.numeric(CumA$coef.estimate)
CumA$int.estimate <- as.numeric(CumA$int.estimate)
CumA$rank <- as.numeric(CumA$rank)
View(preds)
View(AAC.estimates)
#### Required Libraries ####
library(dplyr)
library(ggplot2)
library(CVXR)
library(broom)
#### Simulate the Data ####
##  Define variables
action_codes <- seq(251, 272)
areas <- seq(1, 7)
segments <- seq(1, 20)
##  Create combinations of variables
A <- expand.grid(action_codes, areas, segments)
names(A) <- c("action_code", "area", "segment")
A <- A[with(A, order(action_code, area)),]
A$segment <- rep(sample(1:20, 20, replace = FALSE), 154)
A$dollars <- rep(0,dim(A)[1])
for (i in 1:length(areas)){
for (j in 1:length(action_codes)){
AAC <- max(1500, rnorm(1, mean = 9500, sd = 5000))
A$dollars[((A[,1]==action_codes[j]) & (A[,2]==areas[i]))] <- AAC*
exp(-0.05 * A$segment[((A[,1]==action_codes[j]) & (A[,2]==areas[i]))])
}
}
A$dollars <- round(A$dollars,0)
# Get the cumulative sum dollars so we can optimize on a max objective function
CumA <- A %>%
arrange(action_code, area, segment) %>%
mutate(dollars =  round(dollars,0),
cum.Dol = ave(dollars, cumsum(segment == 1), FUN = cumsum)) %>%
ungroup() %>%
group_by(action_code, area) %>%
mutate(hpc = sample.int(n())) %>%
dplyr::rename(rank = segment)
CumA <- as.data.frame(CumA)
#### Overall Fitted Model ####
# Get a fitted equation for the cumulative dollars (y = 40583ln(x) - 13497)
overallmodel <- nls(cum.Dol ~ coef*log(rank) - int, start = list(coef=40000, int = 10000), data = CumA)
summary(overallmodel)
# Create a model for each AAC
models = CumA %>%
group_by(action_code, area) %>%
do(aac.fit = nls(cum.Dol ~ coef*log(rank) - int, start = list(coef=40000, int = 10000), data = CumA))
# Get the coefficients for each AAC
AAC.estimates <- tidy(models, aac.fit)
AAC.estimates <- data.frame(split(AAC.estimates, AAC.estimates$term))
AAC.estimates <- select(AAC.estimates, coef.action_code, coef.area, coef.estimate, int.estimate)
AAC.estimates <- dplyr::rename(AAC.estimates, action_code = coef.action_code, area = coef.area)
CumA <- merge(CumA, AAC.estimates, by=c("action_code", "area"))
# Get the Predictions for each AAC
preds <- augment(models, aac.fit)
preds <- preds %>%
select(action_code, area, rank, .fitted) %>%
dplyr::rename(predicted = ".fitted")
preds <- unique(preds)
CumA <- merge(CumA, preds, by=c("action_code", "area", "rank"))
# Get the summary statistics
mod.summ <- glance(models, aac.fit)
# Add the overall fitted values to the dataframe
CumA$fitted.overall <- predict(overallmodel)
CumA <- select(CumA, action_code, area, rank, dollars, cum.Dol, hpc, coef.estimate, int.estimate, predicted)
all.params <- overallmodel$m$getPars()
overall.coef <- all.params[1]
overall.int <- all.params[2]
CumA$coef.estimate <- as.numeric(CumA$coef.estimate)
CumA$int.estimate <- as.numeric(CumA$int.estimate)
CumA$rank <- as.numeric(CumA$rank)
#### Overall Optimization on one Objective Function ####
# # Loop through each AAC and run CVX
AAC.Params <- CumA %>%
select(action_code, area, coef.estimate, int.estimate) %>%
unique() %>%
group_by(action_code, area) %>%
mutate(hpc = runif(1, min = 20, max = 200),
hrs.aac = runif(1, min = 100, max = 1000),
historic.aac.starts = runif(1, min = 10, max = 10000),
del.aac.inventory = runif(1, min = 1000, max = 1000000),
user.aac.floor = runif(1, min = 1000, max = 5000),
user.aac.ceiling = runif(1, min = 10000, max = 1000000)) %>%
ungroup() %>%
group_by(area) %>%
mutate(hrs.area = runif(1, min = 10000, max = 100000)) %>%
ungroup()
df <- select(AAC.Params, action_code, area) %>%
mutate(case = NA,
cumulative.dollars = NA)
View(AAC.Params)
View(models)
?nls
View(CumA)
View(models)
?tidy
View(AAC.estimates)
View(df)
#### Required Libraries ####
library(dplyr)
library(ggplot2)
library(CVXR)
library(broom)
#### Simulate the Data ####
##  Define variables
action_codes <- seq(251, 272)
areas <- seq(1, 7)
segments <- seq(1, 20)
##  Create combinations of variables
A <- expand.grid(action_codes, areas, segments)
names(A) <- c("action_code", "area", "segment")
A <- A[with(A, order(action_code, area)),]
A$segment <- rep(sample(1:20, 20, replace = FALSE), 154)
A$dollars <- rep(0,dim(A)[1])
for (i in 1:length(areas)){
for (j in 1:length(action_codes)){
AAC <- max(1500, rnorm(1, mean = 9500, sd = 5000))
A$dollars[((A[,1]==action_codes[j]) & (A[,2]==areas[i]))] <- AAC*
exp(-0.05 * A$segment[((A[,1]==action_codes[j]) & (A[,2]==areas[i]))])
}
}
A$dollars <- round(A$dollars,0)
# Get the cumulative sum dollars so we can optimize on a max objective function
CumA <- A %>%
arrange(action_code, area, segment) %>%
mutate(dollars =  round(dollars,0),
cum.Dol = ave(dollars, cumsum(segment == 1), FUN = cumsum)) %>%
ungroup() %>%
group_by(action_code, area) %>%
mutate(hpc = sample.int(n())) %>%
dplyr::rename(rank = segment)
CumA <- as.data.frame(CumA)
#### Overall Fitted Model ####
# Get a fitted equation for the cumulative dollars (y = 40583ln(x) - 13497)
overallmodel <- nls(cum.Dol ~ coef*log(rank) - int, start = list(coef=40000, int = 10000), data = CumA)
summary(overallmodel)
# Create a model for each AAC
models = CumA %>%
group_by(action_code, area) %>%
do(aac.fit = nls(cum.Dol ~ coef*log(rank) - int, start = list(coef=40000, int = 10000), data = CumA))
# Get the coefficients for each AAC
AAC.estimates <- tidy(models, aac.fit)
AAC.estimates <- data.frame(split(AAC.estimates, AAC.estimates$term))
AAC.estimates <- select(AAC.estimates, coef.action_code, coef.area, coef.estimate, int.estimate)
AAC.estimates <- dplyr::rename(AAC.estimates, action_code = coef.action_code, area = coef.area)
CumA <- merge(CumA, AAC.estimates, by=c("action_code", "area"))
# Get the Predictions for each AAC
preds <- augment(models, aac.fit)
preds <- preds %>%
select(action_code, area, rank, .fitted) %>%
dplyr::rename(predicted = ".fitted")
preds <- unique(preds)
CumA <- merge(CumA, preds, by=c("action_code", "area", "rank"))
# Get the summary statistics
mod.summ <- glance(models, aac.fit)
# Add the overall fitted values to the dataframe
CumA$fitted.overall <- predict(overallmodel)
CumA <- select(CumA, action_code, area, rank, dollars, cum.Dol, hpc, coef.estimate, int.estimate, predicted)
all.params <- overallmodel$m$getPars()
overall.coef <- all.params[1]
overall.int <- all.params[2]
CumA$coef.estimate <- as.numeric(CumA$coef.estimate)
CumA$int.estimate <- as.numeric(CumA$int.estimate)
CumA$rank <- as.numeric(CumA$rank)
#### Overall Optimization on one Objective Function ####
# # Loop through each AAC and run CVX
AAC.Params <- CumA %>%
select(action_code, area, coef.estimate, int.estimate) %>%
unique() %>%
group_by(action_code, area) %>%
mutate(hpc = runif(1, min = 20, max = 200),
hrs.aac = runif(1, min = 100, max = 1000),
historic.aac.starts = runif(1, min = 10, max = 10000),
del.aac.inventory = runif(1, min = 1000, max = 1000000),
user.aac.floor = runif(1, min = 1000, max = 5000),
user.aac.ceiling = runif(1, min = 10000, max = 1000000)) %>%
ungroup() %>%
group_by(area) %>%
mutate(hrs.area = runif(1, min = 10000, max = 100000)) %>%
ungroup()
df <- select(AAC.Params, action_code, area) %>%
mutate(case = NA,
cumulative.dollars = NA)
install.packages("leaflet")
install.packages("DT")
install.packages("data.table")
install.packages("lubridate")
install.packages("shinythemes")
install.packages("rsconnect")
install.packages("shinyBS")
shiny::runApp('Work/Training/RShiny Course/Shiny Intermediate/app skeleton')
library(dplyr)
library(data.table)
#This is my personal folder...
# setwd("~/Work/Training/Data Science Coursera/3-Data Cleansing")
## Code to download zip folder into deafult folder
zipurl = 'https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip'
if (!file.exists('./UCI HAR Dataset.zip')){
download.file(zipurl,'./UCI HAR Dataset.zip', mode = 'wb')
unzip("UCI HAR Dataset.zip", exdir = getwd())
}
###Code to read test and training data
features <- read.table('./UCI HAR Dataset/features.txt')
features <- as.character(features[,2])
train_data_x <- read.table('./UCI HAR Dataset/train/X_train.txt')
train_data_activ <- read.table('./UCI HAR Dataset/train/y_train.txt')
train_data_sub <- read.table('./UCI HAR Dataset/train/subject_train.txt')
data.train <-  as.data.frame(cbind(train_data_sub, train_data_activ, train_data_x))
names(data.train) <- c(c('subject', 'activity'), features)
test_data_x <- read.table('./UCI HAR Dataset/test/X_test.txt')
test_data_activ <- read.table('./UCI HAR Dataset/test/y_test.txt')
test_data_sub <- read.table('./UCI HAR Dataset/test/subject_test.txt')
data.test <-  as.data.frame(cbind(test_data_sub, test_data_activ, test_data_x))
names(data.test) <- c(c('subject', 'activity'), features)
###Merge test and train data
main_DF <- rbind(data.train, data.test)
### Extract only mean and SD related variables
my_variables <- grep('mean|std', names(main_DF))
final_DF <- main_DF[,c(1,2,my_variables)]
#Read activity labels and map to final_DF
activity_labels <- read.table('./UCI HAR Dataset/activity_labels.txt')
activity_labels <- as.character(activity_labels[,2])
final_DF$activity <- activity_labels[final_DF$activity]
###### Name the data set
new_names <- names(final_DF)
new_names <- gsub("[(][)]", "", new_names)
new_names <- gsub("^t", "TimeDomain_", new_names)
new_names <- gsub("^f", "FrequencyDomain_", new_names)
new_names <- gsub("Acc", "Accelerometer", new_names)
new_names <- gsub("Gyro", "Gyroscope", new_names)
new_names <- gsub("Mag", "Magnitude", new_names)
new_names <- gsub("-mean-", "_Mean_", new_names)
new_names <- gsub("-std-", "_StandardDeviation_", new_names)
new_names <- gsub("-", "_", new_names)
names(final_DF) <- new_names
##Get averages set
avg_dataset <- final_DF %>%
group_by(activity, subject) %>%
summarise_all(funs(mean))
#Write text file with new tidy set for averages
write.table(x = avg_dataset, file = "avg_dataset.txt", row.names = FALSE)
run_analysis <- function(){
# Install dplyr package if it is not already installed
if(!require(dplyr)){
install.packages("dplyr")
}
# Load dplyr package
library(dplyr)
# Read the eight relevant text files from the dataset into R
activity_labels <- read.table("UCI HAR Dataset/activity_labels.txt")
features <- read.table("UCI HAR Dataset/features.txt")
subject_test <- read.table("UCI HAR Dataset/test/subject_test.txt")
x_test <- read.table("UCI HAR Dataset/test/X_test.txt")
y_test <- read.table("UCI HAR Dataset/test/y_test.txt")
subject_train <- read.table("UCI HAR Dataset/train/subject_train.txt")
x_train <- read.table("UCI HAR Dataset/train/X_train.txt")
y_train <- read.table("UCI HAR Dataset/train/y_train.txt")
# Create a data frame that replaces the activity id's in y_test with the
# corresponding proper labels
activities_test <- data.frame(Activity = activity_labels$V2[y_test$V1])
#Rename the variable in subject_test to be descriptive
names(subject_test) <- "Subject"
# Create a data frame that replaces the activity id's in y_test with the
# corresponding proper labels
activities_train <- data.frame(Activity = activity_labels$V2[y_train$V1])
# Rename the variable in subject_train to be descriptive
names(subject_train) <- "Subject"
# Create data frames containing the recorded data for the subjects in the
# test and train groups
test <- cbind(subject_test, activities_test, x_test)
train <- cbind(subject_train, activities_train, x_train)
# Combine test and train data frames to create a data frame with the recorded
# data for all subjects. Then arrange the data frames based on the subject being
# observed in ascending order
data <- rbind(test, train)
data <- data %>% arrange(Subject)
# Get the indices for the rows of features corresponding to measurements on the
# mean and standard deviation of each of the features
indices <- grep("mean\\(\\)|std\\(\\)", features$V2)
# Extract a data frame consisting of subject id's, activities, and measurements
# on the mean and standard deviation of each of the features
dataSubset <- data[,c(1, 2, indices + 2)]
# Label the data set with clean, descriptive variable names
names(dataSubset) <- c("SubjectID", "Activity", as.character(features$V2[indices]))
names(dataSubset) <- gsub("-|\\(|\\)", "", names(dataSubset))
names(dataSubset) <- gsub("mean", "Mean", names(dataSubset))
names(dataSubset) <- gsub("std", "Std", names(dataSubset))
# Create a new data frame that groups dataSubset by SubjectID and Activity variables
groupedData <- group_by(dataSubset, SubjectID, Activity)
# Create a new, tidy data frame that contains the mean values of the measurement
# variables in groupedData for each Subject/Activity pair
sumData <- summarize_all(groupedData, mean)
# Return this new data frame
sumData
}
run_analysis <- function(){
# Install dplyr package if it is not already installed
if(!require(dplyr)){
install.packages("dplyr")
}
# Load dplyr package
library(dplyr)
# Read the eight relevant text files from the dataset into R
activity_labels <- read.table("UCI HAR Dataset/activity_labels.txt")
features <- read.table("UCI HAR Dataset/features.txt")
subject_test <- read.table("UCI HAR Dataset/test/subject_test.txt")
x_test <- read.table("UCI HAR Dataset/test/X_test.txt")
y_test <- read.table("UCI HAR Dataset/test/y_test.txt")
subject_train <- read.table("UCI HAR Dataset/train/subject_train.txt")
x_train <- read.table("UCI HAR Dataset/train/X_train.txt")
y_train <- read.table("UCI HAR Dataset/train/y_train.txt")
)
run_analysis <- function(){
# Install dplyr package if it is not already installed
if(!require(dplyr)){
install.packages("dplyr")
}
# Load dplyr package
library(dplyr)
# Read the eight relevant text files from the dataset into R
activity_labels <- read.table("UCI HAR Dataset/activity_labels.txt")
features <- read.table("UCI HAR Dataset/features.txt")
subject_test <- read.table("UCI HAR Dataset/test/subject_test.txt")
x_test <- read.table("UCI HAR Dataset/test/X_test.txt")
y_test <- read.table("UCI HAR Dataset/test/y_test.txt")
subject_train <- read.table("UCI HAR Dataset/train/subject_train.txt")
x_train <- read.table("UCI HAR Dataset/train/X_train.txt")
y_train <- read.table("UCI HAR Dataset/train/y_train.txt")
# Create a data frame that replaces the activity id's in y_test with the
# corresponding proper labels
activities_test <- data.frame(Activity = activity_labels$V2[y_test$V1])
#Rename the variable in subject_test to be descriptive
names(subject_test) <- "Subject"
# Create a data frame that replaces the activity id's in y_test with the
# corresponding proper labels
activities_train <- data.frame(Activity = activity_labels$V2[y_train$V1])
# Rename the variable in subject_train to be descriptive
names(subject_train) <- "Subject"
# Create data frames containing the recorded data for the subjects in the
# test and train groups
test <- cbind(subject_test, activities_test, x_test)
train <- cbind(subject_train, activities_train, x_train)
# Combine test and train data frames to create a data frame with the recorded
# data for all subjects. Then arrange the data frames based on the subject being
# observed in ascending order
data <- rbind(test, train)
data <- data %>% arrange(Subject)
# Get the indices for the rows of features corresponding to measurements on the
# mean and standard deviation of each of the features
indices <- grep("mean\\(\\)|std\\(\\)", features$V2)
# Extract a data frame consisting of subject id's, activities, and measurements
# on the mean and standard deviation of each of the features
dataSubset <- data[,c(1, 2, indices + 2)]
# Label the data set with clean, descriptive variable names
names(dataSubset) <- c("SubjectID", "Activity", as.character(features$V2[indices]))
names(dataSubset) <- gsub("-|\\(|\\)", "", names(dataSubset))
names(dataSubset) <- gsub("mean", "Mean", names(dataSubset))
names(dataSubset) <- gsub("std", "Std", names(dataSubset))
# Create a new data frame that groups dataSubset by SubjectID and Activity variables
groupedData <- group_by(dataSubset, SubjectID, Activity)
# Create a new, tidy data frame that contains the mean values of the measurement
# variables in groupedData for each Subject/Activity pair
sumData <- summarize_all(groupedData, mean)
# Return this new data frame
sumData
}
library('dplyr')
library('dplyr')
Campus <- c('C1', 'c2')
C1_rate1 <- 300
C1_rate2 <- 300
C1_rate3 <- 300
C2_rate1 <- 300
C2_rate2 <- 100
C2_rate3 <- 100
C3_rate1 <- 500
C3_rate2 <- 100
C3_rate3 <- 600
Q1 <- rbind(C1_rate1, C2_rate1, C3_rate1)
Campus <- c('C1', 'c2', 'c3')
Q1 <- cbind(rbind(C1_rate1, C2_rate1, C3_rate1) Campus)
Q1 <- cbind(rbind(C1_rate1, C2_rate1, C3_rate1), Campus)
View(Q1)
Q1 <- expand.grid(cbind(rbind(C1_rate1, C2_rate1, C3_rate1), Campus), 1:13)
View(Q1)
Q1 <- cbind(rbind(C1_rate1, C2_rate1, C3_rate1), Campus)
View(Q1)
View(Q1)
Q1 <- cbind(rbind(rep(C1_rate1, times = 13), C2_rate1, C3_rate1), Campus)
View(Q1)
Q1 <- rbind(rep(C1_rate1, times = 13), rep(C2_rate1, times =13), rep(C3_rate1, times=13))
View(preds)
Q1 <- cbind(rbind(rep(C1_rate1, times = 13), rep(C2_rate1, times =13), rep(C3_rate1, times=13)),
rbind(rep(Campus[1], times = 13), rep(Campus[2], times =13), rep(Campus[3], times=13)))
View(Q1)
Q1 <- as.data.frame(cbind(rbind(rep(C1_rate1, times = 13), rep(C2_rate1, times =13), rep(C3_rate1, times=13)),
rbind(rep(Campus[1], times = 13), rep(Campus[2], times =13), rep(Campus[3], times=13))))
View(Q1)
Q1 <- t(rbind(rep(C1_rate1, times = 13), rep(C2_rate1, times =13), rep(C3_rate1, times=13)))
View(Q1)
Q1 <- rbind(t(rep(C1_rate1, times = 13)), t(rep(C2_rate1, times =13), t(rep(C3_rate1, times=13)))
rbind(rep(Campus[1], times = 13), rep(Campus[2], times =13), rep(Campus[3], times=13))))
Q1 <- rbind(t(rep(C1_rate1, times = 13)), t(rep(C2_rate1, times =13), t(rep(C3_rate1, times=13))))
Q1 <- rbind(t(rep(C1_rate1, times = 13)), t(rep(C2_rate1, times =13)), t(rep(C3_rate1, times=13)))
View(Q1)
Q1 <- cbind(t(rep(C1_rate1, times = 13)), t(rep(C2_rate1, times =13)), t(rep(C3_rate1, times=13)))
View(Q1)
Q1 <- rbind(rep(C1_rate1, times = 13)), rep(C2_rate1, times =13), rep(C3_rate1, times=13))
View(Q1)
dim(q1)
dim(Q1)
str(Q1)
Q1 <- t(rbind(rep(C1_rate1, times = 13)), rep(C2_rate1, times =13), rep(C3_rate1, times=13)))
Q1 <- t(rbind(rep(C1_rate1, times = 13)), rep(C2_rate1, times =13), rep(C3_rate1, times=13))))
Q1 <- t(rbind(rep(C1_rate1, times = 13)), rep(C2_rate1, times =13), rep(C3_rate1, times=13)))
Q1 <- rbind(rep(C1_rate1, times = 13), rep(C2_rate1, times =13), rep(C3_rate1, times=13))
str(Q1)
dim(Q1)
View(Q1)
Q1 <- cbind(rep(C1_rate1, times = 13), rep(C2_rate1, times =13), rep(C3_rate1, times=13))
dim(Q1)
View(Q1)
Q1 <- cbind(rep(C1_rate1, times = 13), rep(C2_rate1, times =13), rep(C3_rate1, times=13))
View(Q1)
Q1 <- rbind(rep(C1_rate1, times = 13), rep(C2_rate1, times =13), rep(C3_rate1, times=13))
View(Q1)
library('dplyr')
Campus <- c('C1', 'c2', 'c3')
C1_rate1 <- 300
C1_rate2 <- 300
C1_rate3 <- 300
C2_rate1 <- 300
C2_rate2 <- 100
C2_rate3 <- 100
C3_rate1 <- 500
C3_rate2 <- 100
C3_rate3 <- 600
C1_rate1 <- rep(C1_rate1, times = 13
C1_rate2 <- 300
C1_rate3 <- 300
C2_rate1 <- 300
C2_rate2 <- 100
C2_rate3 <- 100
C3_rate1 <- 500
C3_rate2 <- 100
C3_rate3 <- 600
Q1 <- rbind(rep(C1_rate1, times = 13)), rep(C2_rate1, times =13), rep(C3_rate1, times=13))
C1_rate1 <- rep(C1_rate1, times = 13)
example(pounts)
example(points)
setwd("~/Work/Training/Data Science Coursera/5-Reproducible Research/Project 1")
library(dyplr)
library(dplyr)
df <- read.csv("activity.csv")
head(df)
str(df)
table(df$interval)
table(df$date)
